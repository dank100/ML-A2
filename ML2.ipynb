{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nMdtSl7yW8Qu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gd-TCxnfYeir"
   },
   "source": [
    "## Dataset and Variables\n",
    "\n",
    "The dataset is a combined dataset from a natural image dataset and an image with text dataset.\n",
    "The first consist of 6,899 images where the classes are: Airplanes, Cars, Cats, Dogs, Flowers, Fruits, Motorcycles and Persons. \n",
    "\n",
    "Load dataset and set training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "EVNTdGiRPYgN",
    "outputId": "81093698-2187-499c-9d4b-35edad7fd3f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ML-A2'...\n",
      "remote: Enumerating objects: 31, done.\u001b[K\n",
      "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 13664 (delta 5), reused 26 (delta 3), pack-reused 13633\u001b[K\n",
      "Receiving objects: 100% (13664/13664), 658.63 MiB | 11.88 MiB/s, done.\n",
      "Resolving deltas: 100% (8/8), done.\n",
      "Checking out files: 100% (12358/12358), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/dank100/ML-A2.git\n",
    "TRAIN_DATA_PATH = \"ML-A2/ImageTextDataSet/train/\"\n",
    "TEST_DATA_PATH = \"ML-A2/ImageTextDataSet/test/\"\n",
    "\n",
    "\n",
    "TRANSFORM_IMG = transforms.Compose(\n",
    "                   [transforms.Resize((32,32)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "classes = ('NoText', 'Text')\n",
    "CLASSES_NUM = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gos9QOt4Yh6X"
   },
   "source": [
    "Load train/test data and create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtenGSOrXIqG"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG)\n",
    "train_data_loader  = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_data = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=TRANSFORM_IMG)\n",
    "test_data_loader  = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAWJut-8YxnT"
   },
   "source": [
    "Define the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZgywqQ5YXNvE"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size = 3)\n",
    "        self.pool = nn.MaxPool2d(stride = 2, kernel_size = 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size = 5)\n",
    "        self.fc1 = nn.Linear(2704, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        #Reduced to number of labels\n",
    "        self.fc3 = nn.Linear(84, CLASSES_NUM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QnjrQfj4Ypu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrinrL_WY0tW"
   },
   "source": [
    "Training, use the training variables to train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "Y7HG-MDUXPvZ",
    "outputId": "eeed127e-ccb0-4778-82d5-682172c6b7f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples:  9948\n",
      "Number of test samples:  2407\n",
      "Detected Classes are:  {'notext': 0, 'text': 1}\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train samples: \", len(train_data))\n",
    "print(\"Number of test samples: \", len(test_data))\n",
    "print(\"Detected Classes are: \", train_data.class_to_idx)\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "model = CNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, data in enumerate(train_data_loader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "itTKFNwWFvE1"
   },
   "source": [
    "# Evaluation\n",
    "Test the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "fvoWGYo0FfWB",
    "outputId": "fefc8ae5-98d6-4aae-b491-1b1944575fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 0, 1, 1, 1])\n",
      "Accuracy of NoText : 90 %\n",
      "Accuracy of  Text : 76 %\n",
      "Accuracy of the network on the test images: 83 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "class_correct = list(0. for i in range(CLASSES_NUM))\n",
    "class_total = list(0. for i in range(CLASSES_NUM))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_data_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        c = (predicted == labels).squeeze()  \n",
    "        for i in range(BATCH_SIZE):\n",
    "            try:\n",
    "              label = labels[i]\n",
    "              class_correct[label] += c[i].item()\n",
    "              class_total[label] += 1\n",
    "            except:\n",
    "              print(labels)\n",
    "\n",
    "\n",
    "for i in range(CLASSES_NUM):\n",
    "  print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    \n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "  100 * correct / total))    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ML2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
